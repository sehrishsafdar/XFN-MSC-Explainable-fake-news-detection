{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HfjOvzB447yQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import XLMRobertaTokenizer, TFXLMRobertaModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Embedding\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import os\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = \"/content/AMMUSED (1).csv\"\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "i5kGMOMh5L5H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Focus on relevant columns\n",
        "comments = dataset['comment'].astype(str)\n",
        "labels = dataset['label_y']\n",
        "\n",
        "# Preprocessing parameters\n",
        "max_vocab_size = 20000\n",
        "max_sequence_length = 100\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)"
      ],
      "metadata": {
        "id": "dxg1LFQr6Ivb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import XLMRobertaTokenizer, TFXLMRobertaModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Embedding\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Import Tokenizer from tensorflow.keras.preprocessing.text and pad_sequences from tensorflow.keras.utils\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences # Import pad_sequences from tensorflow.keras.utils\n",
        "import os\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "RoRoi3zs54GP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and pad the text data\n",
        "tokenizer = Tokenizer(num_words=max_vocab_size)\n",
        "tokenizer.fit_on_texts(comments)\n",
        "sequences = tokenizer.texts_to_sequences(comments)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    padded_sequences, encoded_labels, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "jp6YklYj5aI4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN+LSTM model\n",
        "embedding_dim = 100\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_vocab_size, output_dim=embedding_dim, input_length=max_sequence_length),\n",
        "\n",
        "    # Convolutional layer to extract local features\n",
        "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
        "    MaxPooling1D(pool_size=4),\n",
        "\n",
        "    # LSTM layer to capture sequential dependencies\n",
        "    LSTM(units=128, return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Fully connected layers\n",
        "    Dense(units=64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(units=len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYo0fM2S5y1c",
        "outputId": "95f71c2d-c0a6-4abc-d18f-0106849866ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mRPHDpQ6TiG",
        "outputId": "51871c85-7fb9-4030-8a45-1eeb8a746422"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 132ms/step - accuracy: 0.4843 - loss: 1.1743 - val_accuracy: 0.5809 - val_loss: 1.0157\n",
            "Epoch 2/10\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 127ms/step - accuracy: 0.6552 - loss: 0.8792 - val_accuracy: 0.6219 - val_loss: 0.9250\n",
            "Epoch 3/10\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 129ms/step - accuracy: 0.7754 - loss: 0.6134 - val_accuracy: 0.6007 - val_loss: 1.1044\n",
            "Epoch 4/10\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 139ms/step - accuracy: 0.8543 - loss: 0.4088 - val_accuracy: 0.5971 - val_loss: 1.1542\n",
            "Epoch 5/10\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 129ms/step - accuracy: 0.9001 - loss: 0.2880 - val_accuracy: 0.5832 - val_loss: 1.4907\n",
            "Epoch 6/10\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 128ms/step - accuracy: 0.9179 - loss: 0.2312 - val_accuracy: 0.5750 - val_loss: 1.6035\n",
            "Epoch 7/10\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 127ms/step - accuracy: 0.9360 - loss: 0.1819 - val_accuracy: 0.5588 - val_loss: 1.7351\n",
            "Epoch 8/10\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 126ms/step - accuracy: 0.9386 - loss: 0.1615 - val_accuracy: 0.5732 - val_loss: 2.0635\n",
            "Epoch 9/10\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 128ms/step - accuracy: 0.9422 - loss: 0.1442 - val_accuracy: 0.5725 - val_loss: 2.1543\n",
            "Epoch 10/10\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 134ms/step - accuracy: 0.9461 - loss: 0.1319 - val_accuracy: 0.5760 - val_loss: 2.4346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(f\"Validation Loss: {loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmQeDHo16YyK",
        "outputId": "c542eb42-7769-494c-d2ae-3745ab41eeed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.5752 - loss: 2.4322\n",
            "Validation Loss: 2.4346\n",
            "Validation Accuracy: 0.5760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model for later use\n",
        "model_dir = \"stance_detection_cnn_lstm\"\n",
        "# Add the .keras extension to the file path\n",
        "model.save(model_dir + \".keras\")\n",
        "\n",
        "# Save the model in a zip file\n",
        "zip_file_name = f\"{model_dir}.zip\"\n",
        "with zipfile.ZipFile(zip_file_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, dirs, files in os.walk(model_dir + \".keras\"): # Update the path here too\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            arcname = os.path.relpath(file_path, model_dir + \".keras\") # Update the path here too\n",
        "            zipf.write(file_path, arcname)\n",
        "\n",
        "print(f\"Model successfully saved and zipped as {zip_file_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "170IQTul6cou",
        "outputId": "3251557d-f456-4307-fb95-6c7f54cda193"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully saved and zipped as stance_detection_cnn_lstm.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional epochs with the same model for fine-tuning\n",
        "fine_tuning_epochs = 5\n",
        "fine_tune_history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=batch_size,\n",
        "    epochs=fine_tuning_epochs,\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "vhCI1v8e6gTT",
        "outputId": "63835e72-31a8-4a16-8773-e648ac45fe79"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 124ms/step - accuracy: 0.9481 - loss: 0.1245 - val_accuracy: 0.5664 - val_loss: 2.5803\n",
            "Epoch 2/5\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 127ms/step - accuracy: 0.9495 - loss: 0.1215 - val_accuracy: 0.5809 - val_loss: 2.6077\n",
            "Epoch 3/5\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 125ms/step - accuracy: 0.9482 - loss: 0.1140 - val_accuracy: 0.5713 - val_loss: 2.6909\n",
            "Epoch 4/5\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 132ms/step - accuracy: 0.9465 - loss: 0.1201 - val_accuracy: 0.5733 - val_loss: 2.9276\n",
            "Epoch 5/5\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 128ms/step - accuracy: 0.9508 - loss: 0.1108 - val_accuracy: 0.5752 - val_loss: 3.3944\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=stance_detection_cnn_lstm_finetuned.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e6d3c2d5e7d7>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Save the fine-tuned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfine_tuned_model_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"stance_detection_cnn_lstm_finetuned\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfine_tuned_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfine_tuned_zip_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{fine_tuned_model_dir}.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         )\n\u001b[0;32m--> 114\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;34m\"Invalid filepath extension for saving. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;34m\"Please add either a `.keras` extension for the native Keras \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=stance_detection_cnn_lstm_finetuned."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "fine_tuned_model_dir = \"stance_detection_cnn_lstm_finetuned\"\n",
        "model.save(fine_tuned_model_dir + \".keras\")  # Add the .keras extension here\n",
        "\n",
        "fine_tuned_zip_file = f\"{fine_tuned_model_dir}.zip\"\n",
        "with zipfile.ZipFile(fine_tuned_zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, dirs, files in os.walk(fine_tuned_model_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            arcname = os.path.relpath(file_path, fine_tuned_model_dir)\n",
        "            zipf.write(file_path, arcname)\n",
        "\n",
        "print(f\"Fine-tuned model successfully saved and zipped as {fine_tuned_zip_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMLZLak3_AoY",
        "outputId": "21bb345a-29ad-4243-f5a9-1bcd7ec98dfe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned model successfully saved and zipped as stance_detection_cnn_lstm_finetuned.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on new data\n",
        "new_comments = [\"I completely agree!\", \"I don't think this is correct.\", \"Can you clarify more?\"]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_comments)\n",
        "new_padded = pad_sequences(new_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "predictions = model.predict(new_padded)\n",
        "predicted_labels = label_encoder.inverse_transform(predictions.argmax(axis=1))\n",
        "\n",
        "for comment, label in zip(new_comments, predicted_labels):\n",
        "    print(f\"Comment: {comment} --> Predicted Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LymhzbI96m2G",
        "outputId": "09fc7245-9fd7-452b-8f5e-73ca13de3adf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "Comment: I completely agree! --> Predicted Label: agree\n",
            "Comment: I don't think this is correct. --> Predicted Label: query\n",
            "Comment: Can you clarify more? --> Predicted Label: comment\n"
          ]
        }
      ]
    }
  ]
}