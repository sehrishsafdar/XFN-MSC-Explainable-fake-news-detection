{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e5Urk4zYniqx"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "import os\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = \"/content/AMMUSED (1).csv\"\n",
        "dataset = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "Q3t5iRHIoX5k"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Focus on relevant columns\n",
        "comments = dataset['comment'].astype(str)\n",
        "labels = dataset['label_y']"
      ],
      "metadata": {
        "id": "xstlTVo-om5I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing parameters\n",
        "max_vocab_size = 20000\n",
        "max_sequence_length = 100"
      ],
      "metadata": {
        "id": "9JTkui5vopT4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n"
      ],
      "metadata": {
        "id": "kQDdgv0MosWe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and pad the text data\n",
        "tokenizer = Tokenizer(num_words=max_vocab_size)\n",
        "tokenizer.fit_on_texts(comments)\n",
        "sequences = tokenizer.texts_to_sequences(comments)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)"
      ],
      "metadata": {
        "id": "7pZeeslmovHn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    padded_sequences, encoded_labels, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "_s382ZJloznl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the LSTM model\n",
        "embedding_dim = 100\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_vocab_size, output_dim=embedding_dim, input_length=max_sequence_length),\n",
        "    LSTM(units=128, return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(units=64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(units=len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 3\n",
        "batch_size = 64\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87nHGY5ArYp7",
        "outputId": "18bd05c1-0c8e-46e5-c453-bf7ee9f89b42"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 265ms/step - accuracy: 0.4891 - loss: 1.1551 - val_accuracy: 0.6016 - val_loss: 0.9467\n",
            "Epoch 2/3\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 276ms/step - accuracy: 0.6712 - loss: 0.8144 - val_accuracy: 0.6158 - val_loss: 0.8963\n",
            "Epoch 3/3\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 269ms/step - accuracy: 0.7739 - loss: 0.5816 - val_accuracy: 0.6046 - val_loss: 0.9971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 2\n",
        "batch_size = 32\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCyJJqWKtWQ7",
        "outputId": "b2e01d02-1ee8-4b81-ee08-d53eab9817de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 200ms/step - accuracy: 0.8150 - loss: 0.4894 - val_accuracy: 0.5986 - val_loss: 1.0926\n",
            "Epoch 2/2\n",
            "\u001b[1m795/795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 197ms/step - accuracy: 0.8548 - loss: 0.3756 - val_accuracy: 0.6004 - val_loss: 1.3894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 1\n",
        "batch_size = 8\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm5w5LE8vlZi",
        "outputId": "62560947-c652-441a-f7a0-f7364be900e6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3178/3178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 102ms/step - accuracy: 0.8422 - loss: 0.4121 - val_accuracy: 0.5895 - val_loss: 1.2963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(f\"Validation Loss: {loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-hTpQT5scZK",
        "outputId": "7930542a-76cc-429b-d500-0a089143d762"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.5902 - loss: 1.3090\n",
            "Validation Loss: 1.2963\n",
            "Validation Accuracy: 0.5895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model for later use\n",
        "model_dir = \"stance_detection_lstm.keras\"  # Add .keras extension\n",
        "model.save(model_dir)"
      ],
      "metadata": {
        "id": "3al4pcy_w-z6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model in a zip file\n",
        "zip_file_name = f\"{model_dir}.zip\"\n",
        "with zipfile.ZipFile(zip_file_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, dirs, files in os.walk(model_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            arcname = os.path.relpath(file_path, model_dir)\n",
        "            zipf.write(file_path, arcname)\n",
        "\n",
        "print(f\"Model successfully saved and zipped as {zip_file_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8pt6rSnxMXs",
        "outputId": "68ef6532-fd5d-4388-b4be-7fc9df35c10b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully saved and zipped as stance_detection_lstm.keras.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional epochs with the same model for fine-tuning\n",
        "fine_tuning_epochs = 5\n",
        "fine_tune_history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=batch_size,\n",
        "    epochs=fine_tuning_epochs,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72IygIQpxS2G",
        "outputId": "4ecfeaab-a0ef-45c8-d8bd-e40f26996725"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m3178/3178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 105ms/step - accuracy: 0.8793 - loss: 0.3088 - val_accuracy: 0.5935 - val_loss: 1.5001\n",
            "Epoch 2/5\n",
            "\u001b[1m3178/3178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 102ms/step - accuracy: 0.8970 - loss: 0.2563 - val_accuracy: 0.5848 - val_loss: 1.7145\n",
            "Epoch 3/5\n",
            "\u001b[1m3178/3178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 104ms/step - accuracy: 0.9072 - loss: 0.2227 - val_accuracy: 0.5895 - val_loss: 2.1487\n",
            "Epoch 4/5\n",
            "\u001b[1m3178/3178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 101ms/step - accuracy: 0.9204 - loss: 0.1883 - val_accuracy: 0.5758 - val_loss: 2.1180\n",
            "Epoch 5/5\n",
            "\u001b[1m3178/3178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 101ms/step - accuracy: 0.9271 - loss: 0.1718 - val_accuracy: 0.5772 - val_loss: 2.4117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "fine_tuned_model_dir = \"stance_detection_lstm_finetuned.keras\" # Add .keras extension\n",
        "model.save(fine_tuned_model_dir)\n",
        "\n",
        "fine_tuned_zip_file = f\"{fine_tuned_model_dir}.zip\"\n",
        "with zipfile.ZipFile(fine_tuned_zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, dirs, files in os.walk(fine_tuned_model_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            arcname = os.path.relpath(file_path, fine_tuned_model_dir)\n",
        "            zipf.write(file_path, arcname)\n",
        "\n",
        "print(f\"Fine-tuned model successfully saved and zipped as {fine_tuned_zip_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCIc4f1oyKns",
        "outputId": "fbfb0091-0af6-4b61-a106-26b1f13046bc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned model successfully saved and zipped as stance_detection_lstm_finetuned.keras.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on new data\n",
        "new_comments = [\"I completely agree!\", \"I don't think this is correct.\", \"Can you clarify more?\"]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_comments)\n",
        "new_padded = pad_sequences(new_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "predictions = model.predict(new_padded)\n",
        "predicted_labels = label_encoder.inverse_transform(predictions.argmax(axis=1))\n",
        "\n",
        "for comment, label in zip(new_comments, predicted_labels):\n",
        "    print(f\"Comment: {comment} --> Predicted Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6YM0lhDzMXp",
        "outputId": "e2aa2e23-f3c6-4647-9b7d-df2d6bd8c54d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step\n",
            "Comment: I completely agree! --> Predicted Label: agree\n",
            "Comment: I don't think this is correct. --> Predicted Label: query\n",
            "Comment: Can you clarify more? --> Predicted Label: query\n"
          ]
        }
      ]
    }
  ]
}